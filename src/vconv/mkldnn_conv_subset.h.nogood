// UNUSED -- just pull mkldnn headers verbatim
/*******************************************************************************
* Copyright 2016-2018 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/
#ifndef MKLDNN_CONV_SUBSET_HPP
#define MKLDNN_CONV_SUBSET_HPP
#if defined(MKLDNN_GEMM_SUBSET_HPP)
#error "do not use the gemm subset, convolution needs the full mkldnn headers"
#endif

#include "mkldnn_conv_subset.h" // any local or vgemm extras? define TARGET_VANILLA
#include "mkldnn_types.h"    // pull in mkldnn consts and structs

#include "mkldnn_os.h"
#include <stddef.h>		// ptrdiff_t

#ifdef __cplusplus
extern "C" {
#endif

#define TENSOR_MAX_DIMS 12
/** A type to describe tensor dimensions. */
typedef int mkldnn_dims_t[TENSOR_MAX_DIMS];
/** A type to describe strides within a tensor. */
typedef ptrdiff_t mkldnn_strides_t[TENSOR_MAX_DIMS];

/** Data type specification */
typedef enum {
    /** Undefined data type, used for empty memory descriptors. */
    mkldnn_data_type_undef = 0,
    /** 32-bit/single-precision floating point. */
    mkldnn_f32 = 1,
    /** 32-bit signed integer. */
    mkldnn_s32 = 2,
    /** 16-bit signed integer. */
    mkldnn_s16 = 4,
    /** 8-bit signed integer. */
    mkldnn_s8 = 5,
    /** 8-bit unsigned integer. */
    mkldnn_u8 = 6,
} mkldnn_data_type_t;

typedef enum {
    /** Undefined primitive (XXX: why do we have it?). */
    mkldnn_undefined_primitive,
    /** A memory primitive. */
    mkldnn_memory,
    /** A view primitive. */
    mkldnn_view,
    /** A reorder primitive.*/
    mkldnn_reorder,
    /** A (out-of-place) concat primitive. */
    mkldnn_concat,
    /** A (in-place) concat primitive. */
    mkldnn_concat_inplace,
    /** A sum primitive. */
    mkldnn_sum,
    /** A convolution primitive. */
    mkldnn_convolution,
    /** A deconvolution primitive. */
    mkldnn_deconvolution,
    /** An element-wise primitive. */
    mkldnn_eltwise,
    /** A ReLU primitive. @deprecated */
    mkldnn_relu = mkldnn_eltwise,
    /** A Softmax primitive. */
    mkldnn_softmax,
    /** A pooling primitive. */
    mkldnn_pooling,
    /** An LRN primitive. */
    mkldnn_lrn,
    /** An batch normalization primitive. */
    mkldnn_batch_normalization,
    /** An inner product primitive. */
    mkldnn_inner_product,
    /** A convolution primitive merged with ReLU. @deprecated */
    mkldnn_convolution_relu,
    /** A rnn primitive. */
    mkldnn_rnn,
} mkldnn_primitive_kind_t;

/** Generic description of blocked data layout for most memory formats. */
typedef struct {
    /** Block size for each of the dimensions. */
    mkldnn_dims_t block_dims;
    /** strides[0]: stride between the first elements of adjacent blocks.
     * @n strides[1]: strides between elements in the same block. */
    mkldnn_strides_t strides[2];
    /** Size of the data including padding in each dimension. */
    mkldnn_dims_t padding_dims;
    /** Per-dimension offset from the padding to actual data, the top-level
     * tensor with offsets applied must lie within the padding area. */
    mkldnn_dims_t offset_padding_to_data;
    /** Offset from memory origin to the current block, non-zero only in
     * a description of a memory sub-block. */
    ptrdiff_t offset_padding;
} mkldnn_blocking_desc_t;

/** many of these are not supported :) */
typedef enum {
    /** Undefined memory format, used for empty memory descriptors. */
    mkldnn_format_undef = 0,
    /** Unspecified format. The primitive selects a format
     * automatically. */
    mkldnn_any,
    /** A tensor in a generic format described by the stride and blocking
     * values in each dimension. See #mkldnn_blocking_desc_t for more
     * information. */
    mkldnn_blocked,
    /** 1D data tensor. */
    mkldnn_x,
    /** 2D data tensor. */
    mkldnn_nc,
    /** 4D data tensor in the @c nchw format typically used in Caffe. */
    mkldnn_nchw,
    /** 4D data tensor in the @c nhwc format typically used in TensorFlow. */
    mkldnn_nhwc,
    /** 4D data tensor in the @c chwn format typically used in Neon. */
    mkldnn_chwn,
    /** 4D data tensor in the @c nchw format with channels data laid out in
     * memory in 8-element blocks. */
    mkldnn_nChw8c,
    /** 4D data tensor in the @c nchw format with channels data laid out in
     * memory in 16-element blocks. */
    mkldnn_nChw16c,
    /** 5D data tensor in the @c ncdhw format. */
    mkldnn_ncdhw,
    /** 5D data tensor in the @c ndhwc format typically used in TensorFlow. */
    mkldnn_ndhwc,
    /** 5D data tensor in the @c ncdhw format with channels data laid out in
     * memory in 8-element blocks. */
    mkldnn_nCdhw8c,
    /** 5D data tensor in the @c ncdhw format with channels data laid out in
     * memory in 16-element blocks. */
    mkldnn_nCdhw16c,
    /** 2D weights tensor in the format (input channels, output channels). */
    mkldnn_oi,
    /** 2D weights tensor in the format (input channels, output channels). */
    mkldnn_io,
    /** 4D weights tensor in the format (input channels, output channels,
     * width, height). */
    mkldnn_oihw,
    /** 4D weights tensor in the format (input channels, height, width,
     * output channels). */
    mkldnn_ihwo,
    /** 4D weights tensor in the format (height, width, input channels,
     * output channels). */
    mkldnn_hwio,
    /** 5D weights tensor in the format (depth, height, width, input channels,
     * output channels). */
    mkldnn_dhwio,
    /** 5D weight tensor in the @c oidhw format. */
    mkldnn_oidhw,
   /** 6D weights tensor in the @c oidhw format with output channels data
    * laid out in memory in 8-element blocks and input channels data
     * laid out in memory in 8-element blocks blocked by quadruple. */
    mkldnn_OIdhw8i8o,
    /** 6D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_OIdhw8o8i,
    /** 5D weights tensor in the blocked version of @c oidhw format with output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_Odhwi8o,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 8-element blocks. */
   /** 6D weights tensor in the @c oidhw format with output channels data
    * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 4-element blocks blocked by quadruple. */
    mkldnn_OIdhw16i16o,
    /** 6D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_OIdhw16o16i,
    /** 5D weights tensor in the blocked version of @c oidhw format with output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_Oidhw16o,
    /** 5D weights tensor in the blocked version of @c oidhw format with output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_Odhwi16o,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_OIhw8i8o,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_OIhw16i16o,
    /** 4D weights tensor in the @c oihw format with output channels data
     * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 4-element blocks blocked by quadruple. */
    mkldnn_OIhw4i16o4i,
     /** 4D weights tensor in the @c oihw format with output channels data
      * laid out in memory in 16-element blocks and input channels data
      * laid out in memory in 8-element blocks blocked by pairs. */
    mkldnn_OIhw8i16o2i,
    /** 5D weights tensor in the @c oidhw format with output channels data
     * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 8-element blocks blocked by pairs. */
    mkldnn_OIdhw8i16o2i,
    /** 4D weights tensor in the @c oihw format with input channels data
     * laid out in memory in 16-element blocks and output channels data
     * laid out in memory in 8-element blocks blocked by pairs. */
    mkldnn_OIhw8o16i2o,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_OIhw8o8i,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_OIhw16o16i,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_IOhw16o16i,
    /** 4D weights tensor in the format (output channels, input channels,
     * height, width) with output channels data laid out in memory in 8-element
     * blocks. */
    mkldnn_Oihw8o,
    /** 4D weights tensor in the format (output channels, input channels,
     * height, width) with output channels data laid out in memory in
     * 16-element blocks. */
    mkldnn_Oihw16o,
    /** 4D weights tensor in the format (output channels, width, height, input
     * channels) with output channels data laid out in memory in 8-element
     * blocks. */
    mkldnn_Ohwi8o,
    /** 4D weights tensor in the format (output channels, width, height, input
     * channels) with output channels data laid out in memory in 16-element
     * blocks. */
    mkldnn_Ohwi16o,
    /** 4D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 16-element and 4-element blocks. */
    mkldnn_OhIw16o4i,
    /** 5D weights tensor in the @c oihw format with extra outer dimension for
     * groups. */
    mkldnn_goihw,
    /** 5D weights tensor in the @c hwio format with extra dimension for
     * groups that comes after the output channels. */
    mkldnn_hwigo,
    /** 6D weights tensor in the @c oidhw format with output channels data
     * laid out in memory in 8-element blocks and input channels data
     * laid out in memory in 8-element blocks blocked by quadruple. */
    mkldnn_gOIdhw8i8o,
    /** 6D weights tensor in the @c oihw format with both input and output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_gOIdhw8o8i,
    /** 5D weights tensor in the blocked version of @c oidhw format with output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_gOdhwi8o,
    /** 5D weights tensor in the blocked version of @c goihw format with both
     * input and output channels data laid out in memory in 8-element blocks.
     */
    mkldnn_gOIhw8i8o,
    /** 5D weights tensor in the blocked version of @c goihw format with both
     * input and output channels data laid out in memory in 16-element blocks.
     */
    mkldnn_gOIhw16i16o,
    /** 5D weights tensor in the @c oihw format with output channels data
     * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 4-element blocks blocked by quadruple. */
    mkldnn_gOIhw4i16o4i,
    /** 5D weights tensor in the @c oihw format with output channels data
     * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 8-element blocks blocked by pairs. */
    mkldnn_gOIhw8i16o2i,
    /** 6D weights tensor in the @c oidhw format with output channels data
     * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 8-element blocks blocked by pairs. */
    mkldnn_gOIdhw8i16o2i,
    /** 5D weights tensor in the @c oihw format with input channels data
     * laid out in memory in 16-element blocks and output channels data
     * laid out in memory in 8-element blocks blocked by pairs. */
    mkldnn_gOIhw8o16i2o,
    /** 5D weights tensor in the blocked version of @c goihw format with both
     * input and output channels data laid out in memory in 8-element blocks.
     */
    mkldnn_gOIhw8o8i,
    /** 5D weights tensor in the blocked version of @c goihw format with both
     * input and output channels data laid out in memory in 16-element blocks.
     */
    mkldnn_gOIhw16o16i,
    /** 5D weights tensor in the blocked version of @c goihw format with both
     * input and output channels data laid out in memory in 16-element blocks.
     */
    mkldnn_gIOhw16o16i,
    /** 5D weights tensor in the blocked version of @c goihw format with output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_gOihw8o,
    /** 5D weights tensor in the blocked version of @c goihw format with output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_gOihw16o,
    /** 5D weights tensor in the blocked version of @c goihw format with output
     * channels data laid out in memory in 8-element blocks. */
    mkldnn_gOhwi8o,
    /** 5D weights tensor in the blocked version of @c goihw format with output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_gOhwi16o,
    /** 5D weights tensor in the blocked version of @c goihw format with group
     * data laid out in memory in 8-element blocks. */
    mkldnn_Goihw8g,
    /** 5D weights tensor in the blocked version of @c goihw format with group
     * data laid out in memory in 16-element blocks. */
    mkldnn_Goihw16g,
    /** 5D weights tensor in the @c goihw format with both input and output
     * channels data laid out in memory in 16-element and 4-element blocks. */
    mkldnn_gOhIw16o4i,
    /** 6D weight tensor in the @c goidhw format with extra dimension for
     * groups */
    mkldnn_goidhw,
   /** 6D weights tensor in the @c oidhw format with output channels data
    * laid out in memory in 16-element blocks and input channels data
     * laid out in memory in 4-element blocks blocked by quadruple. */
    mkldnn_gOIdhw16i16o,
    /** 6D weights tensor in the blocked version of @c goihw format with both
     * input and output channels data laid out in memory in 16-element blocks.
     */
    mkldnn_gOIdhw16o16i,
    /** 6D weights tensor in the blocked version of @c goidhw format with output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_gOidhw16o,
    /** 6D weights tensor in the blocked version of @c goidhw format with output
     * channels data laid out in memory in 16-element blocks. */
    mkldnn_gOdhwi16o,
    /** 3D data tensor in the format (batch, seq_length, input channels). */
    mkldnn_ntc,
    /** 3D data tensor in the format (seq_length, batch, input channels). */
    mkldnn_tnc,
    /** 5D states tensor in the format (num_layers, num_directions, num_states,
     * batch, state channels). */
    mkldnn_ldsnc,
    /** 5D weights tensor in the format (num_layers, num_directions,
     *  input_chanels, num_gates, output_channels). */
    mkldnn_ldigo,
    /** 5D weights tensor in the blocked format. */
    mkldnn_ldigo_p,
    /** 5D weights tensor in the format (num_layers, num_directions, num_gates,
     *  output_channels, input_chanels). */
    mkldnn_ldgoi,
    /** 5D weights tensor in the blocked format. */
    mkldnn_ldgoi_p,
    /** 4D bias tensor in the format (num_layers, num_directions, num_gates,
     * output_channels). */
    mkldnn_ldgo,
    /** General tensor format for integer 8bit winograd convolution. */
    mkldnn_wino_fmt,
    /** Just a sentinel, not real memory format. Must be changed after new
     * format is added. */
    mkldnn_format_last,
    /** 4D weights tensor in the oihw format with input channels data laid out
     * in memory in 8-element blocks. */
    mkldnn_oIhw8i = mkldnn_nChw8c,
    /** 4D weights tensor in the oihw format with input channels data laid out
     * in memory in 16-element blocks. */
    mkldnn_oIhw16i = mkldnn_nChw16c,
    /** 5D weights tensor in the oihw format with input channels data laid out
     * in memory in 8-element blocks. */
    mkldnn_oIdhw8i = mkldnn_nCdhw8c,
    /** 5D weights tensor in the oihw format with input channels data laid out
     * in memory in 16-element blocks. */
    mkldnn_oIdhw16i = mkldnn_nCdhw16c,
} mkldnn_memory_format_t;

typedef struct {
    //mkldnn_wino_memory_format_t wino_format;
    //int r;
    //int alpha;
    //int ic;
    //int oc;
    //int ic_block;
    //int oc_block;
    //int ic2_block;
    //int oc2_block;
    //size_t size;
} mkldnn_wino_desc_t;

typedef struct {
    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_memory. */
    mkldnn_primitive_kind_t primitive_kind;
    /** Number of dimensions */
    int ndims;
    /** Dimensions in the following order: mini-batch, channel, spatial. For
     * example: <code>{N, C, H, W}</code>. */
    mkldnn_dims_t dims;
    /** Data type of the tensor elements. */
    mkldnn_data_type_t data_type;
    /** Memory format. */
    mkldnn_memory_format_t format;
    union {
        /** Description of the data layout for memory formats that use
         * blocking. */
        mkldnn_blocking_desc_t blocking;
        /** Tensor of weights for integer 8bit winograd convolution. */
        mkldnn_wino_desc_t wino_desc;
        /* ... other descriptions possible */
    } layout_desc;
} mkldnn_memory_desc_t;

/** Kinds of propagation. */
typedef enum {
    /* TODO: suggest renames */
    /** Undefined propagation type. */
    mkldnn_prop_kind_undef = 0,
    /** Forward data propagation (training mode). In this mode primitives
     * perform computations necessary for subsequent backward propagation. */
    mkldnn_forward_training = 64,
    /** Forward data propagation (inference mode). In this mode primitives only
     * perform computations that are necessary for inference and omit
     * computations that are only necessary for backward propagation. */
    mkldnn_forward_inference = 96,
    /** Forward data propagation (alias for @c mkldnn_forward_inference) */
    mkldnn_forward_scoring = mkldnn_forward_inference,
   /** Forward data propagation (alias for @c mkldnn_forward_training) */
    mkldnn_forward = mkldnn_forward_training,
    /** Backward propagation (with respect to all parameters */
    mkldnn_backward = 128,
    /** Backward data propagation */
    mkldnn_backward_data = 160,
    /** Backward weights propagation */
    mkldnn_backward_weights = 192,
    /** Backward bias propagation */
    mkldnn_backward_bias = 193,
} mkldnn_prop_kind_t;

/** A descriptor of a convolution operation. */
typedef struct {
    /** The kind of primitive. Used for self identifying the primitive
     * descriptor. Must be #mkldnn_convolution. */
    mkldnn_primitive_kind_t primitive_kind;
    /** The kind of propagation. Possible values: #mkldnn_forward_training,
     * #mkldnn_forward_inference, #mkldnn_backward_data,
     * #mkldnn_backward_weights, and #mkldnn_backward_bias. */
    mkldnn_prop_kind_t prop_kind;
    /** The kind of the convolution algorithm. Possible values:
     * #mkldnn_convolution_direct. */
    mkldnn_alg_kind_t alg_kind;
    /** Source memory descriptor. */
    mkldnn_memory_desc_t src_desc;
    /** Source gradient memory descriptor. */
    mkldnn_memory_desc_t diff_src_desc;
    /** Weights memory descriptor. */
    mkldnn_memory_desc_t weights_desc;
    /** Weights gradient memory descriptor. */
    mkldnn_memory_desc_t diff_weights_desc;
    /** Bias memory descriptor. */
    mkldnn_memory_desc_t bias_desc;
    /** Bias gradient memory descriptor. */
    mkldnn_memory_desc_t diff_bias_desc;
    /** Destination memory descriptor. */
    mkldnn_memory_desc_t dst_desc;
    /** Destination gradient memory descriptor. */
    mkldnn_memory_desc_t diff_dst_desc;
    /** Convolution strides in each spatial dimension. */
    mkldnn_dims_t strides;
    /** Convolution dilates in each spatial dimension. */
    mkldnn_dims_t dilates;
    /** Padding in each spatial dimension. padding[0] is a padding in the
     * beginning (@p padding_l), padding[1] is a padding in the end (@p
     * padding_r). */
    mkldnn_dims_t padding[2];
    /** The kind of padding to use. */
    mkldnn_padding_kind_t padding_kind;
    /** The accumulator data type. Initialized automatically. */
    mkldnn_data_type_t accum_data_type;
} mkldnn_convolution_desc_t;

#ifdef __cplusplus
}
#endif

using blocking_desc_t = mkldnn_blocking_desc_t;
using wino_data_t = mkldnn_wino_desc_t;

using data_type_t = mkldnn_data_type_t;
namespace data_type {
    const data_type_t undef = mkldnn_data_type_undef;
    const data_type_t f32 = mkldnn_f32;
    const data_type_t s32 = mkldnn_s32;
    const data_type_t s16 = mkldnn_s16;
    const data_type_t s8 = mkldnn_s8;
    const data_type_t u8 = mkldnn_u8;
}

using primitive_kind_t = mkldnn_primitive_kind_t;
namespace primitive_kind {
    const primitive_kind_t undefined = mkldnn_undefined_primitive;
    const primitive_kind_t memory = mkldnn_memory;
    const primitive_kind_t view = mkldnn_view;
    const primitive_kind_t reorder = mkldnn_reorder;
    const primitive_kind_t concat = mkldnn_concat;
    const primitive_kind_t concat_inplace = mkldnn_concat_inplace;
    const primitive_kind_t sum = mkldnn_sum;
    const primitive_kind_t convolution = mkldnn_convolution;
    const primitive_kind_t deconvolution = mkldnn_deconvolution;
    const primitive_kind_t eltwise = mkldnn_eltwise;
    const primitive_kind_t softmax = mkldnn_softmax;
    const primitive_kind_t pooling = mkldnn_pooling;
    const primitive_kind_t lrn = mkldnn_lrn;
    const primitive_kind_t batch_normalization = mkldnn_batch_normalization;
    const primitive_kind_t inner_product = mkldnn_inner_product;
    const primitive_kind_t convolution_relu = mkldnn_convolution_relu;
    const primitive_kind_t rnn = mkldnn_rnn;
}

using prop_kind_t = mkldnn_prop_kind_t;
namespace prop_kind {
    const prop_kind_t undef = mkldnn_prop_kind_undef;
    const prop_kind_t forward_training = mkldnn_forward_training;
    const prop_kind_t forward_inference = mkldnn_forward_inference;
    const prop_kind_t forward_scoring = mkldnn_forward_scoring;
    const prop_kind_t forward = mkldnn_forward;
    const prop_kind_t backward = mkldnn_backward;
    const prop_kind_t backward_data = mkldnn_backward_data;
    const prop_kind_t backward_weights = mkldnn_backward_weights;
    const prop_kind_t backward_bias = mkldnn_backward_bias;
}

using memory_format_t = mkldnn_memory_format_t;
namespace memory_format {
    const memory_format_t undef = mkldnn_format_undef;
    const memory_format_t any = mkldnn_any;
    const memory_format_t blocked = mkldnn_blocked;
    const memory_format_t x = mkldnn_x;
    const memory_format_t nc = mkldnn_nc;
    const memory_format_t nchw = mkldnn_nchw;
    const memory_format_t nhwc = mkldnn_nhwc;
    const memory_format_t chwn = mkldnn_chwn;
#if 0 || MKLDNN_JIT_TYPES > 0
    const memory_format_t nChw8c = mkldnn_nChw8c;
    const memory_format_t nChw16c = mkldnn_nChw16c;
#endif
    const memory_format_t ncdhw = mkldnn_ncdhw;
    const memory_format_t ndhwc = mkldnn_ndhwc;
#if 0 || MKLDNN_JIT_TYPES > 0
    const memory_format_t nCdhw8c = mkldnn_nCdhw8c;
    const memory_format_t nCdhw16c = mkldnn_nCdhw16c;
#endif
    const memory_format_t oi = mkldnn_oi;
    const memory_format_t io = mkldnn_io;
    const memory_format_t oihw = mkldnn_oihw;
    const memory_format_t ihwo = mkldnn_ihwo;
    const memory_format_t hwio = mkldnn_hwio;
    const memory_format_t dhwio = mkldnn_dhwio;
    const memory_format_t oidhw = mkldnn_oidhw;
#if 0 || MKLDNN_JIT_TYPES > 0
    const memory_format_t OIdhw8i8o = mkldnn_OIdhw8i8o;
    const memory_format_t OIdhw8o8i = mkldnn_OIdhw8o8i;
    const memory_format_t Odhwi8o = mkldnn_Odhwi8o;
    const memory_format_t OIdhw16i16o = mkldnn_OIdhw16i16o;
    const memory_format_t OIdhw16o16i = mkldnn_OIdhw16o16i;
    const memory_format_t Oidhw16o = mkldnn_Oidhw16o;
    const memory_format_t Odhwi16o = mkldnn_Odhwi16o;
    const memory_format_t oIhw8i = mkldnn_oIhw8i;
    const memory_format_t oIhw16i = mkldnn_oIhw16i;
    const memory_format_t oIdhw8i = mkldnn_oIdhw8i;
    const memory_format_t oIdhw16i = mkldnn_oIdhw16i;
    const memory_format_t OIhw8i8o = mkldnn_OIhw8i8o;
    const memory_format_t OIhw16i16o = mkldnn_OIhw16i16o;
    const memory_format_t OIhw4i16o4i = mkldnn_OIhw4i16o4i;
    const memory_format_t OIhw8i16o2i = mkldnn_OIhw8i16o2i;
    const memory_format_t OIdhw8i16o2i = mkldnn_OIdhw8i16o2i;
    const memory_format_t OIhw8o16i2o = mkldnn_OIhw8o16i2o;
    const memory_format_t OIhw8o8i = mkldnn_OIhw8o8i;
    const memory_format_t OIhw16o16i = mkldnn_OIhw16o16i;
    const memory_format_t IOhw16o16i = mkldnn_IOhw16o16i;
    const memory_format_t Oihw16o = mkldnn_Oihw16o;
    const memory_format_t Ohwi8o = mkldnn_Ohwi8o;
    const memory_format_t Ohwi16o = mkldnn_Ohwi16o;
    //const memory_format_t OhIw16o4i = mkldnn_OhIw16o4i;
#endif
    const memory_format_t goihw = mkldnn_goihw;
    const memory_format_t hwigo = mkldnn_hwigo;
#if 0 || MKLDNN_JIT_TYPES > 0
    const memory_format_t gOIhw8i8o = mkldnn_gOIhw8i8o;
    const memory_format_t gOIhw16i16o = mkldnn_gOIhw16i16o;
    const memory_format_t gOIhw4i16o4i = mkldnn_gOIhw4i16o4i;
    const memory_format_t gOIhw8i16o2i = mkldnn_gOIhw8i16o2i;
    const memory_format_t gOIdhw8i16o2i = mkldnn_gOIdhw8i16o2i;
    const memory_format_t gOIhw8o16i2o = mkldnn_gOIhw8o16i2o;
    const memory_format_t gOIhw8o8i = mkldnn_gOIhw8o8i;
    const memory_format_t gOIhw16o16i = mkldnn_gOIhw16o16i;
    const memory_format_t gIOhw16o16i = mkldnn_gIOhw16o16i;
    const memory_format_t gOihw16o = mkldnn_gOihw16o;
    const memory_format_t gOhwi8o = mkldnn_gOhwi8o;
    const memory_format_t gOhwi16o = mkldnn_gOhwi16o;
    const memory_format_t Goihw8g = mkldnn_Goihw8g;
    const memory_format_t Goihw16g = mkldnn_Goihw16g;
    //const memory_format_t gOhIw16o4i = mkldnn_gOhIw16o4i;
#endif
    const memory_format_t goidhw = mkldnn_goidhw;
#if 0 || MKLDNN_JIT_TYPES > 0
    const memory_format_t gOIdhw8i8o = mkldnn_gOIdhw8i8o;
    const memory_format_t gOIdhw8o8i = mkldnn_gOIdhw8o8i;
    const memory_format_t gOdhwi8o = mkldnn_gOdhwi8o;
    const memory_format_t gOIdhw16i16o = mkldnn_gOIdhw16i16o;
    const memory_format_t gOIdhw16o16i = mkldnn_gOIdhw16o16i;
    const memory_format_t gOidhw16o = mkldnn_gOidhw16o;
    const memory_format_t gOdhwi16o = mkldnn_gOdhwi16o;
#endif
    const memory_format_t ntc = mkldnn_ntc;
    const memory_format_t tnc = mkldnn_tnc;
    const memory_format_t ldsnc = mkldnn_ldsnc;
    const memory_format_t ldigo = mkldnn_ldigo;
    const memory_format_t ldigo_p = mkldnn_ldigo_p;
    const memory_format_t ldgoi = mkldnn_ldgoi;
    const memory_format_t ldgoi_p = mkldnn_ldgoi_p;
    const memory_format_t ldgo = mkldnn_ldgo;
    const memory_format_t wino_fmt = mkldnn_wino_fmt;
}

using data_type_t = mkldnn_data_type_t;
namespace data_type {
    const data_type_t undef = mkldnn_data_type_undef;
    const data_type_t f32 = mkldnn_f32;
    const data_type_t s32 = mkldnn_s32;
    const data_type_t s16 = mkldnn_s16;
    const data_type_t s8 = mkldnn_s8;
    const data_type_t u8 = mkldnn_u8;
}

using memory_desc_t = mkldnn_memory_desc_t;
using convolution_desc_t = mkldnn_convolution_desc_t;
using deconvolution_desc_t = mkldnn_deconvolution_desc_t;

#endif // MKLDNN_CONV_SUBSET_HPP
